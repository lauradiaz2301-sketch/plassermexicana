{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lauradiaz2301-sketch/plassermexicana/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading the Dataset from Zenodo\n",
        "\n",
        "In this section, we automatically retrieve all files stored in a Zenodo record using its REST API.\n",
        "\n",
        "#### What this script does\n",
        "\n",
        "1. Connects to Zenodo using the recordâ€™s API endpoint  \n",
        "2. Retrieves the metadata for the dataset  \n",
        "3. Iterates through all available files  \n",
        "4. Downloads each file directly into the Colab environment  \n",
        "5. Saves them locally with their original filenames  \n",
        "\n",
        "#### Notes\n",
        "- The API link retrieves metadata even without a token.\n",
        "- The token included in the record URL is **not required** for file downloads when using the public API.\n",
        "- Downloading via the JSON API is the safest way to ensure you grab every file in the dataset.\n",
        "\n",
        "Run the next cell to perform a full automatic download.\n"
      ],
      "metadata": {
        "id": "hf5t_RI_bxYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# ============================================================\n",
        "# 1. Zenodo record URL\n",
        "# ------------------------------------------------------------\n",
        "# The first URL contains a token, but we will instead use the\n",
        "# official Zenodo API endpoint to retrieve metadata.\n",
        "# ============================================================\n",
        "\n",
        "url = \"https://zenodo.org/records/17687977?token=eyJhbGciOiJIUzUxMiJ9.eyJpZCI6ImU0ZTY5MzY1LTMzMTctNDE2Mi04NjUyLThiNGZiMmJkYjhhZiIsImRhdGEiOnt9LCJyYW5kb20iOiI5ZTk4ZGNkNzYxNTMxNmU2YmU5NWVmNDU5YzBhZTExOCJ9.yUINW5E-ZBIesHydD_BigcwPPqTD8uHlz070SmC1qbCIbHem8TS-Iv53sEWmICyovCBBqzCkPcq-B6blKSPIWA\"\n",
        "\n",
        "# ============================================================\n",
        "# 2. Zenodo API endpoint (public metadata)\n",
        "# ------------------------------------------------------------\n",
        "# This returns a JSON object containing:\n",
        "#   - Record title\n",
        "#   - Authors\n",
        "#   - All files inside the dataset\n",
        "#   - Download links for each file\n",
        "# ============================================================\n",
        "\n",
        "api_url = \"https://zenodo.org/api/records/17687977\"\n",
        "record = requests.get(api_url).json()  # Fetch metadata as JSON\n",
        "\n",
        "# ============================================================\n",
        "# 3. Iterating through all files in the deposit\n",
        "# ------------------------------------------------------------\n",
        "# The JSON structure contains a \"files\" list.\n",
        "# Each entry has:\n",
        "#   - f[\"key\"]      â†’ filename\n",
        "#   - f[\"links\"]    â†’ dictionary containing download links\n",
        "# We iterate and download each file one by one.\n",
        "# ============================================================\n",
        "\n",
        "for f in record[\"files\"]:\n",
        "    # Construct direct download URL\n",
        "    file_url = f[\"links\"][\"self\"] + \"?download=1\"\n",
        "    file_name = f[\"key\"]\n",
        "\n",
        "    print(f\"Downloading {file_name}...\")\n",
        "\n",
        "    # Perform HTTP GET request\n",
        "    r = requests.get(file_url)\n",
        "\n",
        "    # Save file locally in binary mode\n",
        "    with open(file_name, \"wb\") as file:\n",
        "        file.write(r.content)\n",
        "\n",
        "# ============================================================\n",
        "# 4. Completion message\n",
        "# ============================================================\n",
        "\n",
        "print(\"âœ“ All files downloaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rHXWwxuSoRI",
        "outputId": "4884aa47-3941-488c-c7f1-c6070ab1ea3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descargando synthetic_timeseries_sample_10k.csv...\n",
            "âœ“ Descarga completa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uploading a CSV File into Google Colab\n",
        "\n",
        "In this step, we allow the user to upload a CSV file directly from their computer into the Colab environment.\n",
        "\n",
        "#### What this cell does\n",
        "\n",
        "1. Opens a file-picker dialog in Colab  \n",
        "2. Receives the uploaded file as a binary dictionary  \n",
        "3. Extracts the filename automatically  \n",
        "4. Loads the CSV into a Pandas DataFrame  \n",
        "5. Displays the first rows to confirm successful upload  \n",
        "\n",
        "This is useful when you want to incrementally add new rows, validate external datasets, or run inference on new unseen data.\n"
      ],
      "metadata": {
        "id": "yNwJgBj-b1VI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "print(\"ðŸ“¤ Upload the CSV file containing the new rows:\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# This command opens a file-selection window in Google Colab.\n",
        "# The result is a dictionary where:\n",
        "#   key   = file name (string)\n",
        "#   value = raw binary content\n",
        "# -----------------------------------------------------------\n",
        "uploaded = files.upload()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Extract the actual file name from the dictionary.\n",
        "# This allows us to handle uploads without hardcoding names.\n",
        "# -----------------------------------------------------------\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "print(f\"File received: {file_name}\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Read the uploaded CSV into a pandas DataFrame.\n",
        "# Pandas handles the in-memory binary content seamlessly.\n",
        "# -----------------------------------------------------------\n",
        "df_new = pd.read_csv(file_name)\n",
        "\n",
        "print(\"âœ“ File successfully loaded into a DataFrame.\")\n",
        "df_new.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "cnUls2NkS33o",
        "outputId": "937db5c6-e028-43a6-b7b7-70fc2e42b3e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sube el archivo CSV con nuevas filas:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2e6926f2-4511-44e0-b810-39524c15f067\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2e6926f2-4511-44e0-b810-39524c15f067\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sat_data_eg.csv to sat_data_eg.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading the Uploaded CSV File\n",
        "\n",
        "After uploading the file using `files.upload()`, we extract the filename and load\n",
        "its contents into a Pandas DataFrame.\n",
        "\n",
        "#### What this cell does:\n",
        "1. Retrieves the uploaded filename from the `uploaded` dictionary  \n",
        "2. Reads the CSV into a DataFrame  \n",
        "3. Prints a confirmation message  \n",
        "4. Displays the first rows to verify that the data loaded correctly  \n"
      ],
      "metadata": {
        "id": "l1zTo_AIcN_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Extract the filename from the `uploaded` dictionary.\n",
        "# The dictionary format is: { \"filename.csv\": binary_content }\n",
        "# ------------------------------------------------------------\n",
        "new_file_name = list(uploaded.keys())[0]\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Load the CSV file into a pandas DataFrame.\n",
        "# Pandas can read the file directly from its name since Colab\n",
        "# stores uploaded files in the working directory.\n",
        "# ------------------------------------------------------------\n",
        "new_data = pd.read_csv(new_file_name)\n",
        "\n",
        "print(\"âœ“ File successfully loaded:\", new_file_name)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Display the first rows for a quick inspection\n",
        "# ------------------------------------------------------------\n",
        "new_data.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "bBwshOPMUGW9",
        "outputId": "3b302935-a427-4340-f6c8-e258c35e6185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Archivo cargado: sat_data_eg.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              timestamp      site_id  synth_point_id        lat        lon  \\\n",
              "0  2025-10-25T00:00:00Z  line85_ord0  line85_ord0_p0  19.281079 -99.697361   \n",
              "1  2025-10-26T00:00:00Z  line85_ord0  line85_ord0_p0  19.281079 -99.697361   \n",
              "2  2025-10-27T00:00:00Z  line85_ord0  line85_ord0_p0  19.281079 -99.697361   \n",
              "3  2025-10-28T00:00:00Z  line85_ord0  line85_ord0_p0  19.281079 -99.697361   \n",
              "4  2025-10-29T00:00:00Z  line85_ord0  line85_ord0_p0  19.281079 -99.697361   \n",
              "\n",
              "   epsg           sensor  resolution_m      NDVI      NDWI  ...  score_BSI  \\\n",
              "0  4326  S1+S2_synthetic            10  0.574513 -0.164946  ...   0.417363   \n",
              "1  4326  S1+S2_synthetic            10  0.555201 -0.176713  ...   0.303721   \n",
              "2  4326  S1+S2_synthetic            10  0.559921 -0.182879  ...   0.347308   \n",
              "3  4326  S1+S2_synthetic            10  0.514147 -0.161355  ...   0.361979   \n",
              "4  4326  S1+S2_synthetic            10  0.585262 -0.151374  ...   0.386241   \n",
              "\n",
              "   score_NBR  score_clay  score_insar  score_amplitude  score_overall  \\\n",
              "0   0.037452    0.074776            1         0.446513       0.340149   \n",
              "1   0.157122    0.061819            1         0.403192       0.353115   \n",
              "2   0.158219    0.021435            1         0.385135       0.355681   \n",
              "3   0.169940    0.000000            1         0.424853       0.383636   \n",
              "4   0.190391    0.000000            1         0.097054       0.339294   \n",
              "\n",
              "                                               flags  seed  is_bad_track  \\\n",
              "0  [\"critical_threshold\", \"insar_critical\", \"synt...    42          True   \n",
              "1  [\"critical_threshold\", \"insar_critical\", \"synt...    42          True   \n",
              "2  [\"critical_threshold\", \"insar_critical\", \"synt...    42          True   \n",
              "3  [\"critical_threshold\", \"insar_critical\", \"synt...    42          True   \n",
              "4  [\"critical_threshold\", \"insar_critical\", \"synt...    42          True   \n",
              "\n",
              "                                               notes  \n",
              "0  synthetic generator; insar_rate_mm_per_year=33...  \n",
              "1  synthetic generator; insar_rate_mm_per_year=33...  \n",
              "2  synthetic generator; insar_rate_mm_per_year=33...  \n",
              "3  synthetic generator; insar_rate_mm_per_year=33...  \n",
              "4  synthetic generator; insar_rate_mm_per_year=33...  \n",
              "\n",
              "[5 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3090bbe-3291-4400-813e-44efc6c418ad\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>site_id</th>\n",
              "      <th>synth_point_id</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>epsg</th>\n",
              "      <th>sensor</th>\n",
              "      <th>resolution_m</th>\n",
              "      <th>NDVI</th>\n",
              "      <th>NDWI</th>\n",
              "      <th>...</th>\n",
              "      <th>score_BSI</th>\n",
              "      <th>score_NBR</th>\n",
              "      <th>score_clay</th>\n",
              "      <th>score_insar</th>\n",
              "      <th>score_amplitude</th>\n",
              "      <th>score_overall</th>\n",
              "      <th>flags</th>\n",
              "      <th>seed</th>\n",
              "      <th>is_bad_track</th>\n",
              "      <th>notes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-10-25T00:00:00Z</td>\n",
              "      <td>line85_ord0</td>\n",
              "      <td>line85_ord0_p0</td>\n",
              "      <td>19.281079</td>\n",
              "      <td>-99.697361</td>\n",
              "      <td>4326</td>\n",
              "      <td>S1+S2_synthetic</td>\n",
              "      <td>10</td>\n",
              "      <td>0.574513</td>\n",
              "      <td>-0.164946</td>\n",
              "      <td>...</td>\n",
              "      <td>0.417363</td>\n",
              "      <td>0.037452</td>\n",
              "      <td>0.074776</td>\n",
              "      <td>1</td>\n",
              "      <td>0.446513</td>\n",
              "      <td>0.340149</td>\n",
              "      <td>[\"critical_threshold\", \"insar_critical\", \"synt...</td>\n",
              "      <td>42</td>\n",
              "      <td>True</td>\n",
              "      <td>synthetic generator; insar_rate_mm_per_year=33...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-10-26T00:00:00Z</td>\n",
              "      <td>line85_ord0</td>\n",
              "      <td>line85_ord0_p0</td>\n",
              "      <td>19.281079</td>\n",
              "      <td>-99.697361</td>\n",
              "      <td>4326</td>\n",
              "      <td>S1+S2_synthetic</td>\n",
              "      <td>10</td>\n",
              "      <td>0.555201</td>\n",
              "      <td>-0.176713</td>\n",
              "      <td>...</td>\n",
              "      <td>0.303721</td>\n",
              "      <td>0.157122</td>\n",
              "      <td>0.061819</td>\n",
              "      <td>1</td>\n",
              "      <td>0.403192</td>\n",
              "      <td>0.353115</td>\n",
              "      <td>[\"critical_threshold\", \"insar_critical\", \"synt...</td>\n",
              "      <td>42</td>\n",
              "      <td>True</td>\n",
              "      <td>synthetic generator; insar_rate_mm_per_year=33...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-10-27T00:00:00Z</td>\n",
              "      <td>line85_ord0</td>\n",
              "      <td>line85_ord0_p0</td>\n",
              "      <td>19.281079</td>\n",
              "      <td>-99.697361</td>\n",
              "      <td>4326</td>\n",
              "      <td>S1+S2_synthetic</td>\n",
              "      <td>10</td>\n",
              "      <td>0.559921</td>\n",
              "      <td>-0.182879</td>\n",
              "      <td>...</td>\n",
              "      <td>0.347308</td>\n",
              "      <td>0.158219</td>\n",
              "      <td>0.021435</td>\n",
              "      <td>1</td>\n",
              "      <td>0.385135</td>\n",
              "      <td>0.355681</td>\n",
              "      <td>[\"critical_threshold\", \"insar_critical\", \"synt...</td>\n",
              "      <td>42</td>\n",
              "      <td>True</td>\n",
              "      <td>synthetic generator; insar_rate_mm_per_year=33...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-10-28T00:00:00Z</td>\n",
              "      <td>line85_ord0</td>\n",
              "      <td>line85_ord0_p0</td>\n",
              "      <td>19.281079</td>\n",
              "      <td>-99.697361</td>\n",
              "      <td>4326</td>\n",
              "      <td>S1+S2_synthetic</td>\n",
              "      <td>10</td>\n",
              "      <td>0.514147</td>\n",
              "      <td>-0.161355</td>\n",
              "      <td>...</td>\n",
              "      <td>0.361979</td>\n",
              "      <td>0.169940</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.424853</td>\n",
              "      <td>0.383636</td>\n",
              "      <td>[\"critical_threshold\", \"insar_critical\", \"synt...</td>\n",
              "      <td>42</td>\n",
              "      <td>True</td>\n",
              "      <td>synthetic generator; insar_rate_mm_per_year=33...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-10-29T00:00:00Z</td>\n",
              "      <td>line85_ord0</td>\n",
              "      <td>line85_ord0_p0</td>\n",
              "      <td>19.281079</td>\n",
              "      <td>-99.697361</td>\n",
              "      <td>4326</td>\n",
              "      <td>S1+S2_synthetic</td>\n",
              "      <td>10</td>\n",
              "      <td>0.585262</td>\n",
              "      <td>-0.151374</td>\n",
              "      <td>...</td>\n",
              "      <td>0.386241</td>\n",
              "      <td>0.190391</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.097054</td>\n",
              "      <td>0.339294</td>\n",
              "      <td>[\"critical_threshold\", \"insar_critical\", \"synt...</td>\n",
              "      <td>42</td>\n",
              "      <td>True</td>\n",
              "      <td>synthetic generator; insar_rate_mm_per_year=33...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 32 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3090bbe-3291-4400-813e-44efc6c418ad')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e3090bbe-3291-4400-813e-44efc6c418ad button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e3090bbe-3291-4400-813e-44efc6c418ad');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-939edf88-33c3-4f53-adfb-c9d2aa55ac98\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-939edf88-33c3-4f53-adfb-c9d2aa55ac98')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-939edf88-33c3-4f53-adfb-c9d2aa55ac98 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "new_data"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Original Dataset\n",
        "\n",
        "In this step, we load the original dataset that was previously uploaded through\n",
        "`files.upload()`.\n",
        "\n",
        "#### How this works\n",
        "\n",
        "- The variable `file_name` must already contain the name of the uploaded file  \n",
        "  (coming from: `file_name = list(uploaded.keys())[0]`).\n",
        "- We use this filename to read the CSV into a Pandas DataFrame.\n",
        "- Finally, we print a confirmation message and preview the first rows to verify\n",
        "  that the dataset loaded correctly.\n"
      ],
      "metadata": {
        "id": "rDi0d9Jccdm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Load the original dataset using the filename obtained from\n",
        "# the previous upload step:\n",
        "#     file_name = list(uploaded.keys())[0]\n",
        "#\n",
        "# This assumes that `file_name` already exists in memory.\n",
        "# ------------------------------------------------------------\n",
        "original_data = pd.read_csv(file_name)\n",
        "\n",
        "print(\"âœ“ Original dataset loaded successfully.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Display the first few rows for quick inspection.\n",
        "# This helps verify column names, formatting, and content.\n",
        "# ------------------------------------------------------------\n",
        "original_data.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "uLNnS1q-USu7",
        "outputId": "f98ed57b-a7df-4c5c-d8a1-3dc49063e3a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Base original cargada\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id             timestamp      site_id  synth_point_id        lat  \\\n",
              "0  rec_1  2025-10-25T00:00:00Z  line85_ord0  line85_ord0_p0  19.281079   \n",
              "1  rec_2  2025-10-26T00:00:00Z  line85_ord0  line85_ord0_p0  19.281079   \n",
              "2  rec_3  2025-10-27T00:00:00Z  line85_ord0  line85_ord0_p0  19.281079   \n",
              "3  rec_4  2025-10-28T00:00:00Z  line85_ord0  line85_ord0_p0  19.281079   \n",
              "4  rec_5  2025-10-29T00:00:00Z  line85_ord0  line85_ord0_p0  19.281079   \n",
              "\n",
              "         lon  epsg           sensor  resolution_m      NDVI  ...  score_BSI  \\\n",
              "0 -99.697361  4326  S1+S2_synthetic            10  0.574513  ...   0.417363   \n",
              "1 -99.697361  4326  S1+S2_synthetic            10  0.555201  ...   0.303721   \n",
              "2 -99.697361  4326  S1+S2_synthetic            10  0.559921  ...   0.347308   \n",
              "3 -99.697361  4326  S1+S2_synthetic            10  0.514147  ...   0.361979   \n",
              "4 -99.697361  4326  S1+S2_synthetic            10  0.585262  ...   0.386241   \n",
              "\n",
              "   score_NBR  score_clay  score_insar  score_amplitude  score_overall  \\\n",
              "0   0.037452    0.074776          1.0         0.446513       0.340149   \n",
              "1   0.157122    0.061819          1.0         0.403192       0.353115   \n",
              "2   0.158219    0.021435          1.0         0.385135       0.355681   \n",
              "3   0.169940    0.000000          1.0         0.424853       0.383636   \n",
              "4   0.190391    0.000000          1.0         0.097054       0.339294   \n",
              "\n",
              "                                               flags  seed  is_bad_track  \\\n",
              "0  [\"critical_threshold\", \"insar_critical\", \"synt...    42          True   \n",
              "1  [\"critical_threshold\", \"insar_critical\", \"synt...    42          True   \n",
              "2  [\"critical_threshold\", \"insar_critical\", \"synt...    42          True   \n",
              "3  [\"critical_threshold\", \"insar_critical\", \"synt...    42          True   \n",
              "4  [\"critical_threshold\", \"insar_critical\", \"synt...    42          True   \n",
              "\n",
              "                                               notes  \n",
              "0  synthetic generator; insar_rate_mm_per_year=33...  \n",
              "1  synthetic generator; insar_rate_mm_per_year=33...  \n",
              "2  synthetic generator; insar_rate_mm_per_year=33...  \n",
              "3  synthetic generator; insar_rate_mm_per_year=33...  \n",
              "4  synthetic generator; insar_rate_mm_per_year=33...  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43eff716-53d3-4fa9-8a1e-43196a06e22d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>site_id</th>\n",
              "      <th>synth_point_id</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>epsg</th>\n",
              "      <th>sensor</th>\n",
              "      <th>resolution_m</th>\n",
              "      <th>NDVI</th>\n",
              "      <th>...</th>\n",
              "      <th>score_BSI</th>\n",
              "      <th>score_NBR</th>\n",
              "      <th>score_clay</th>\n",
              "      <th>score_insar</th>\n",
              "      <th>score_amplitude</th>\n",
              "      <th>score_overall</th>\n",
              "      <th>flags</th>\n",
              "      <th>seed</th>\n",
              "      <th>is_bad_track</th>\n",
              "      <th>notes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rec_1</td>\n",
              "      <td>2025-10-25T00:00:00Z</td>\n",
              "      <td>line85_ord0</td>\n",
              "      <td>line85_ord0_p0</td>\n",
              "      <td>19.281079</td>\n",
              "      <td>-99.697361</td>\n",
              "      <td>4326</td>\n",
              "      <td>S1+S2_synthetic</td>\n",
              "      <td>10</td>\n",
              "      <td>0.574513</td>\n",
              "      <td>...</td>\n",
              "      <td>0.417363</td>\n",
              "      <td>0.037452</td>\n",
              "      <td>0.074776</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.446513</td>\n",
              "      <td>0.340149</td>\n",
              "      <td>[\"critical_threshold\", \"insar_critical\", \"synt...</td>\n",
              "      <td>42</td>\n",
              "      <td>True</td>\n",
              "      <td>synthetic generator; insar_rate_mm_per_year=33...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rec_2</td>\n",
              "      <td>2025-10-26T00:00:00Z</td>\n",
              "      <td>line85_ord0</td>\n",
              "      <td>line85_ord0_p0</td>\n",
              "      <td>19.281079</td>\n",
              "      <td>-99.697361</td>\n",
              "      <td>4326</td>\n",
              "      <td>S1+S2_synthetic</td>\n",
              "      <td>10</td>\n",
              "      <td>0.555201</td>\n",
              "      <td>...</td>\n",
              "      <td>0.303721</td>\n",
              "      <td>0.157122</td>\n",
              "      <td>0.061819</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.403192</td>\n",
              "      <td>0.353115</td>\n",
              "      <td>[\"critical_threshold\", \"insar_critical\", \"synt...</td>\n",
              "      <td>42</td>\n",
              "      <td>True</td>\n",
              "      <td>synthetic generator; insar_rate_mm_per_year=33...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rec_3</td>\n",
              "      <td>2025-10-27T00:00:00Z</td>\n",
              "      <td>line85_ord0</td>\n",
              "      <td>line85_ord0_p0</td>\n",
              "      <td>19.281079</td>\n",
              "      <td>-99.697361</td>\n",
              "      <td>4326</td>\n",
              "      <td>S1+S2_synthetic</td>\n",
              "      <td>10</td>\n",
              "      <td>0.559921</td>\n",
              "      <td>...</td>\n",
              "      <td>0.347308</td>\n",
              "      <td>0.158219</td>\n",
              "      <td>0.021435</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.385135</td>\n",
              "      <td>0.355681</td>\n",
              "      <td>[\"critical_threshold\", \"insar_critical\", \"synt...</td>\n",
              "      <td>42</td>\n",
              "      <td>True</td>\n",
              "      <td>synthetic generator; insar_rate_mm_per_year=33...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rec_4</td>\n",
              "      <td>2025-10-28T00:00:00Z</td>\n",
              "      <td>line85_ord0</td>\n",
              "      <td>line85_ord0_p0</td>\n",
              "      <td>19.281079</td>\n",
              "      <td>-99.697361</td>\n",
              "      <td>4326</td>\n",
              "      <td>S1+S2_synthetic</td>\n",
              "      <td>10</td>\n",
              "      <td>0.514147</td>\n",
              "      <td>...</td>\n",
              "      <td>0.361979</td>\n",
              "      <td>0.169940</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.424853</td>\n",
              "      <td>0.383636</td>\n",
              "      <td>[\"critical_threshold\", \"insar_critical\", \"synt...</td>\n",
              "      <td>42</td>\n",
              "      <td>True</td>\n",
              "      <td>synthetic generator; insar_rate_mm_per_year=33...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rec_5</td>\n",
              "      <td>2025-10-29T00:00:00Z</td>\n",
              "      <td>line85_ord0</td>\n",
              "      <td>line85_ord0_p0</td>\n",
              "      <td>19.281079</td>\n",
              "      <td>-99.697361</td>\n",
              "      <td>4326</td>\n",
              "      <td>S1+S2_synthetic</td>\n",
              "      <td>10</td>\n",
              "      <td>0.585262</td>\n",
              "      <td>...</td>\n",
              "      <td>0.386241</td>\n",
              "      <td>0.190391</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.097054</td>\n",
              "      <td>0.339294</td>\n",
              "      <td>[\"critical_threshold\", \"insar_critical\", \"synt...</td>\n",
              "      <td>42</td>\n",
              "      <td>True</td>\n",
              "      <td>synthetic generator; insar_rate_mm_per_year=33...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43eff716-53d3-4fa9-8a1e-43196a06e22d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-43eff716-53d3-4fa9-8a1e-43196a06e22d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-43eff716-53d3-4fa9-8a1e-43196a06e22d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ee3bf533-20b1-4f88-a8d1-725dabbced6f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee3bf533-20b1-4f88-a8d1-725dabbced6f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ee3bf533-20b1-4f88-a8d1-725dabbced6f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "original_data"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validating Column Structure of the Newly Uploaded File\n",
        "\n",
        "Before merging datasets, it is essential to ensure that the new CSV file has  \n",
        "**exactly the same structure as the original dataset**, except for the ID column,\n",
        "which will be generated later.\n",
        "\n",
        "#### What this cell does\n",
        "\n",
        "1. Detects the **ID column name** from the original dataset (usually the first column).\n",
        "2. Extracts the list of **expected columns** (all columns except the ID).\n",
        "3. Compares these expected columns with the actual column names in `new_data`.\n",
        "4. If the structure does not match, raises an error with a clear explanation.\n",
        "5. If everything matches, inserts a blank ID column into `new_data` so it can be\n",
        "   assigned sequential IDs later.\n",
        "\n",
        "This strict validation prevents merging incompatible datasets and avoids silent\n",
        "structural errors that could break the model pipeline.\n"
      ],
      "metadata": {
        "id": "-ALi8rKFdkWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Identify the name of the ID column in the original dataset.\n",
        "# Assumption: the ID column is always the first column.\n",
        "# Example: \"id\"\n",
        "# ------------------------------------------------------------\n",
        "id_col = original_data.columns[0]\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Build the list of columns expected in the new data.\n",
        "# This includes every column EXCEPT the ID, which will be generated.\n",
        "# ------------------------------------------------------------\n",
        "expected_columns = list(original_data.columns[1:])\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Extract the actual column list from the newly uploaded dataset.\n",
        "# This allows us to compare the structures.\n",
        "# ------------------------------------------------------------\n",
        "new_columns = list(new_data.columns)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Compare expected columns vs. uploaded columns.\n",
        "# If they don't match *exactly*, raise an explicit error.\n",
        "# ------------------------------------------------------------\n",
        "if new_columns != expected_columns:\n",
        "    raise ValueError(\n",
        "        \"âŒ ERROR: The uploaded file does not match the expected structure.\\n\"\n",
        "        f\"Expected columns (without ID): {expected_columns}\\n\"\n",
        "        f\"Received columns: {new_columns}\"\n",
        "    )\n",
        "\n",
        "print(\"âœ“ Column structure validated successfully (ID excluded).\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Insert an empty ID column so that new rows can be assigned\n",
        "# unique IDs later when the datasets are merged.\n",
        "# ------------------------------------------------------------\n",
        "new_data.insert(0, id_col, None)\n",
        "\n",
        "print(f\"âœ“ Temporary ID column '{id_col}' added to new_data.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqveQ3Y1V0uS",
        "outputId": "dcbb933f-dae6-4da3-db08-844c0bfaf55f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Columnas vÃ¡lidas (sin ID).\n",
            "âœ“ Columna 'id' agregada temporalmente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating New Sequential IDs for the Uploaded Rows\n",
        "\n",
        "The original dataset uses an ID format of the type:\n",
        "\n",
        "\n",
        "Before merging newly uploaded data into the main database, we must assign new\n",
        "unique IDs that:\n",
        "\n",
        "1. Follow the same naming convention (`rec_x`)  \n",
        "2. Continue the sequence without breaking it  \n",
        "3. Preserve consistent and traceable indexing across the dataset  \n",
        "\n",
        "### ðŸ” What this cell does\n",
        "\n",
        "1. Reads the name of the ID column from the original dataset  \n",
        "2. Extracts all existing `rec_x` identifiers  \n",
        "3. Parses the numeric part (`x`)  \n",
        "4. Identifies the maximum existing ID  \n",
        "5. Generates a new set of IDs for the uploaded rows:  \n",
        "   - Example: if the last ID is `rec_150`, the new rows get:  \n",
        "     `rec_151`, `rec_152`, `rec_153`, ...  \n",
        "6. Assigns these new IDs to the new DataFrame  \n",
        "\n",
        "This guarantees that the combined dataset will have a **clean, continuous, and\n",
        "non-overlapping** ID sequence.\n"
      ],
      "metadata": {
        "id": "VVEzfGhYd1Lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Identify the name of the ID column in the original dataset.\n",
        "# Assumption: the ID column is always the first column.\n",
        "# Example: \"id\" with values like \"rec_123\"\n",
        "# ------------------------------------------------------------\n",
        "id_col = original_data.columns[0]\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Extract the existing IDs and convert them to strings.\n",
        "# We must ensure consistent format for parsing.\n",
        "# ------------------------------------------------------------\n",
        "original_ids = original_data[id_col].astype(str)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Helper function to extract the numeric part from IDs\n",
        "# formatted as \"rec_x\". For example:\n",
        "#   \"rec_25\" â†’ 25\n",
        "# If the ID doesn't follow the expected pattern, return None.\n",
        "# ------------------------------------------------------------\n",
        "def extract_num(rec):\n",
        "    try:\n",
        "        return int(rec.split(\"_\")[1])\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Apply the extraction function to all IDs, drop invalid results,\n",
        "# and convert to integer.\n",
        "# ------------------------------------------------------------\n",
        "id_numbers = original_ids.apply(extract_num).dropna().astype(int)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Find the highest numeric ID currently in the dataset.\n",
        "# This defines the starting point for new IDs.\n",
        "# ------------------------------------------------------------\n",
        "max_existing_id = id_numbers.max()\n",
        "print(\"Last existing ID:\", max_existing_id)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Generate a list of new sequential IDs for the uploaded rows.\n",
        "# If max_existing_id = 150 and new_data has 3 rows â†’ new IDs:\n",
        "#   rec_151, rec_152, rec_153\n",
        "# ------------------------------------------------------------\n",
        "new_ids = [f\"rec_{max_existing_id + i + 1}\" for i in range(len(new_data))]\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Assign the generated IDs to the new_data DataFrame.\n",
        "# The 'id_col' name dynamically adapts to the dataset (e.g. \"id\").\n",
        "# ------------------------------------------------------------\n",
        "new_data[id_col] = new_ids\n",
        "\n",
        "print(\"âœ“ New IDs generated successfully.\")\n",
        "new_data.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "5ef8vGoYWmaV",
        "outputId": "b35e654a-0cd5-4275-ccfd-b14681e960e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ãšltimo ID existente: 40000\n",
            "âœ“ Nuevos IDs generados:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id             timestamp      site_id  synth_point_id        lat  \\\n",
              "0  rec_40001  2025-10-25T00:00:00Z  line85_ord0  line85_ord0_p0  19.281079   \n",
              "1  rec_40002  2025-10-26T00:00:00Z  line85_ord0  line85_ord0_p0  19.281079   \n",
              "2  rec_40003  2025-10-27T00:00:00Z  line85_ord0  line85_ord0_p0  19.281079   \n",
              "3  rec_40004  2025-10-28T00:00:00Z  line85_ord0  line85_ord0_p0  19.281079   \n",
              "4  rec_40005  2025-10-29T00:00:00Z  line85_ord0  line85_ord0_p0  19.281079   \n",
              "\n",
              "         lon  epsg           sensor  resolution_m      NDVI  ...  score_BSI  \\\n",
              "0 -99.697361  4326  S1+S2_synthetic            10  0.574513  ...   0.417363   \n",
              "1 -99.697361  4326  S1+S2_synthetic            10  0.555201  ...   0.303721   \n",
              "2 -99.697361  4326  S1+S2_synthetic            10  0.559921  ...   0.347308   \n",
              "3 -99.697361  4326  S1+S2_synthetic            10  0.514147  ...   0.361979   \n",
              "4 -99.697361  4326  S1+S2_synthetic            10  0.585262  ...   0.386241   \n",
              "\n",
              "   score_NBR  score_clay  score_insar  score_amplitude  score_overall  \\\n",
              "0   0.037452    0.074776            1         0.446513       0.340149   \n",
              "1   0.157122    0.061819            1         0.403192       0.353115   \n",
              "2   0.158219    0.021435            1         0.385135       0.355681   \n",
              "3   0.169940    0.000000            1         0.424853       0.383636   \n",
              "4   0.190391    0.000000            1         0.097054       0.339294   \n",
              "\n",
              "                                               flags  seed  is_bad_track  \\\n",
              "0  [\"critical_threshold\", \"insar_critical\", \"synt...    42          True   \n",
              "1  [\"critical_threshold\", \"insar_critical\", \"synt...    42          True   \n",
              "2  [\"critical_threshold\", \"insar_critical\", \"synt...    42          True   \n",
              "3  [\"critical_threshold\", \"insar_critical\", \"synt...    42          True   \n",
              "4  [\"critical_threshold\", \"insar_critical\", \"synt...    42          True   \n",
              "\n",
              "                                               notes  \n",
              "0  synthetic generator; insar_rate_mm_per_year=33...  \n",
              "1  synthetic generator; insar_rate_mm_per_year=33...  \n",
              "2  synthetic generator; insar_rate_mm_per_year=33...  \n",
              "3  synthetic generator; insar_rate_mm_per_year=33...  \n",
              "4  synthetic generator; insar_rate_mm_per_year=33...  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d3e0ec0-176a-4a3d-898b-386ccd7c4c60\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>site_id</th>\n",
              "      <th>synth_point_id</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>epsg</th>\n",
              "      <th>sensor</th>\n",
              "      <th>resolution_m</th>\n",
              "      <th>NDVI</th>\n",
              "      <th>...</th>\n",
              "      <th>score_BSI</th>\n",
              "      <th>score_NBR</th>\n",
              "      <th>score_clay</th>\n",
              "      <th>score_insar</th>\n",
              "      <th>score_amplitude</th>\n",
              "      <th>score_overall</th>\n",
              "      <th>flags</th>\n",
              "      <th>seed</th>\n",
              "      <th>is_bad_track</th>\n",
              "      <th>notes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rec_40001</td>\n",
              "      <td>2025-10-25T00:00:00Z</td>\n",
              "      <td>line85_ord0</td>\n",
              "      <td>line85_ord0_p0</td>\n",
              "      <td>19.281079</td>\n",
              "      <td>-99.697361</td>\n",
              "      <td>4326</td>\n",
              "      <td>S1+S2_synthetic</td>\n",
              "      <td>10</td>\n",
              "      <td>0.574513</td>\n",
              "      <td>...</td>\n",
              "      <td>0.417363</td>\n",
              "      <td>0.037452</td>\n",
              "      <td>0.074776</td>\n",
              "      <td>1</td>\n",
              "      <td>0.446513</td>\n",
              "      <td>0.340149</td>\n",
              "      <td>[\"critical_threshold\", \"insar_critical\", \"synt...</td>\n",
              "      <td>42</td>\n",
              "      <td>True</td>\n",
              "      <td>synthetic generator; insar_rate_mm_per_year=33...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rec_40002</td>\n",
              "      <td>2025-10-26T00:00:00Z</td>\n",
              "      <td>line85_ord0</td>\n",
              "      <td>line85_ord0_p0</td>\n",
              "      <td>19.281079</td>\n",
              "      <td>-99.697361</td>\n",
              "      <td>4326</td>\n",
              "      <td>S1+S2_synthetic</td>\n",
              "      <td>10</td>\n",
              "      <td>0.555201</td>\n",
              "      <td>...</td>\n",
              "      <td>0.303721</td>\n",
              "      <td>0.157122</td>\n",
              "      <td>0.061819</td>\n",
              "      <td>1</td>\n",
              "      <td>0.403192</td>\n",
              "      <td>0.353115</td>\n",
              "      <td>[\"critical_threshold\", \"insar_critical\", \"synt...</td>\n",
              "      <td>42</td>\n",
              "      <td>True</td>\n",
              "      <td>synthetic generator; insar_rate_mm_per_year=33...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rec_40003</td>\n",
              "      <td>2025-10-27T00:00:00Z</td>\n",
              "      <td>line85_ord0</td>\n",
              "      <td>line85_ord0_p0</td>\n",
              "      <td>19.281079</td>\n",
              "      <td>-99.697361</td>\n",
              "      <td>4326</td>\n",
              "      <td>S1+S2_synthetic</td>\n",
              "      <td>10</td>\n",
              "      <td>0.559921</td>\n",
              "      <td>...</td>\n",
              "      <td>0.347308</td>\n",
              "      <td>0.158219</td>\n",
              "      <td>0.021435</td>\n",
              "      <td>1</td>\n",
              "      <td>0.385135</td>\n",
              "      <td>0.355681</td>\n",
              "      <td>[\"critical_threshold\", \"insar_critical\", \"synt...</td>\n",
              "      <td>42</td>\n",
              "      <td>True</td>\n",
              "      <td>synthetic generator; insar_rate_mm_per_year=33...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rec_40004</td>\n",
              "      <td>2025-10-28T00:00:00Z</td>\n",
              "      <td>line85_ord0</td>\n",
              "      <td>line85_ord0_p0</td>\n",
              "      <td>19.281079</td>\n",
              "      <td>-99.697361</td>\n",
              "      <td>4326</td>\n",
              "      <td>S1+S2_synthetic</td>\n",
              "      <td>10</td>\n",
              "      <td>0.514147</td>\n",
              "      <td>...</td>\n",
              "      <td>0.361979</td>\n",
              "      <td>0.169940</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.424853</td>\n",
              "      <td>0.383636</td>\n",
              "      <td>[\"critical_threshold\", \"insar_critical\", \"synt...</td>\n",
              "      <td>42</td>\n",
              "      <td>True</td>\n",
              "      <td>synthetic generator; insar_rate_mm_per_year=33...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rec_40005</td>\n",
              "      <td>2025-10-29T00:00:00Z</td>\n",
              "      <td>line85_ord0</td>\n",
              "      <td>line85_ord0_p0</td>\n",
              "      <td>19.281079</td>\n",
              "      <td>-99.697361</td>\n",
              "      <td>4326</td>\n",
              "      <td>S1+S2_synthetic</td>\n",
              "      <td>10</td>\n",
              "      <td>0.585262</td>\n",
              "      <td>...</td>\n",
              "      <td>0.386241</td>\n",
              "      <td>0.190391</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.097054</td>\n",
              "      <td>0.339294</td>\n",
              "      <td>[\"critical_threshold\", \"insar_critical\", \"synt...</td>\n",
              "      <td>42</td>\n",
              "      <td>True</td>\n",
              "      <td>synthetic generator; insar_rate_mm_per_year=33...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d3e0ec0-176a-4a3d-898b-386ccd7c4c60')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3d3e0ec0-176a-4a3d-898b-386ccd7c4c60 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3d3e0ec0-176a-4a3d-898b-386ccd7c4c60');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-00a15150-05bf-43cc-8eea-95dce87cc429\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-00a15150-05bf-43cc-8eea-95dce87cc429')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-00a15150-05bf-43cc-8eea-95dce87cc429 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "new_data"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merging the Original Dataset with the Newly Uploaded Rows\n",
        "\n",
        "Now that:\n",
        "- the new file has been validated,\n",
        "- its structure matches the original dataset,\n",
        "- and new sequential IDs (`rec_x`) have been generated,\n",
        "\n",
        "we can safely append the new rows to the original database.\n",
        "\n",
        "#### What this cell does\n",
        "\n",
        "1. Concatenates the original dataset and the new rows into a single DataFrame  \n",
        "2. Resets the index to keep the structure clean  \n",
        "3. Saves the updated dataset as `database_actualizada.csv`  \n",
        "4. Automatically triggers a download so the updated file can be stored locally  \n",
        "\n",
        "This ensures your master dataset stays consistent, versioned, and ready for the\n",
        "next training cycle.\n"
      ],
      "metadata": {
        "id": "zXfVcoXoeEw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Concatenate the original dataset with the new rows.\n",
        "# 'ignore_index=True' ensures the final DataFrame has a clean\n",
        "# continuous index (0, 1, 2, ...).\n",
        "# ------------------------------------------------------------\n",
        "updated_data = pd.concat([original_data, new_data], ignore_index=True)\n",
        "\n",
        "print(\"âœ“ Original data and new rows successfully merged.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Define the output filename for the updated dataset.\n",
        "# ------------------------------------------------------------\n",
        "updated_filename = \"database_actualizada.csv\"\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Save the merged DataFrame to disk without including the index.\n",
        "# This ensures the file has only the intended columns.\n",
        "# ------------------------------------------------------------\n",
        "updated_data.to_csv(updated_filename, index=False)\n",
        "\n",
        "print(\"âœ“ Updated dataset saved as:\", updated_filename)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Trigger download of the updated file in Google Colab.\n",
        "# This allows the user to store the updated dataset locally.\n",
        "# ------------------------------------------------------------\n",
        "from google.colab import files\n",
        "files.download(updated_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "33SwIDrOWqns",
        "outputId": "4c4dd09c-cee4-470f-f223-44f7a3eba942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Base de datos actualizada guardada como: database_actualizada.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_874bac5c-39e9-479d-979b-dd47d2a1c9c5\", \"database_actualizada.csv\", 17694719)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸš† Satellite-Based Density Regression Model  \n",
        "### Predicting Track Condition / Priority Index from Satellite Data\n",
        "\n",
        "This notebook trains a **Random Forest regression model** to estimate a continuous variable called **density**, which we interpret as:\n",
        "- Track condition  \n",
        "- Risk level  \n",
        "- Priority score for maintenance  \n",
        "\n",
        "The workflow consists of:\n",
        "\n",
        "1. **Loading and inspecting the dataset**\n",
        "2. **Selecting satellite-derived features**\n",
        "3. **Splitting the dataset into training/testing**\n",
        "4. **Training a RandomForest regressor**\n",
        "5. **Saving the model to `.pkl`**\n",
        "6. **Evaluating performance (MAE, RMSE, RÂ²)**\n",
        "7. **Visualizing predictions vs. ground truth**\n",
        "\n",
        "This notebook is structured and documented for clarity and reproducibility.\n"
      ],
      "metadata": {
        "id": "EoNg0ZUGQUWZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQpXcUMHQGV0"
      },
      "outputs": [],
      "source": [
        "# =====================================================\n",
        "# Libraries\n",
        "# =====================================================\n",
        "\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Load Dataset\n",
        "\n",
        "We load the preprocessed satellite dataset.  \n",
        "Each row represents a *track segment* or *time window*, containing:\n",
        "\n",
        "- Spectral indices (NDVI, NDWI, NDMI, NBR)\n",
        "- Soil / moisture information\n",
        "- Radar amplitude components\n",
        "- Derived scoring functions for each feature\n",
        "\n",
        "The target variable **density** is continuous and represents our maintenance priority index.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wA0gi-V5Yzgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 1. Load Data\n",
        "# =====================================================\n",
        "\n",
        "df = pd.read_csv(\"/content/database_actualizada.csv\")\n",
        "\n",
        "print(\"Dataset loaded successfully!\")\n",
        "print(df.head())\n",
        "print(df.describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1KNO5vfYhNp",
        "outputId": "0ada7da3-e52b-423f-868e-de181ebf76d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully!\n",
            "      id             timestamp      site_id  synth_point_id        lat  \\\n",
            "0  rec_1  2025-10-25T00:00:00Z  line85_ord0  line85_ord0_p0  19.281079   \n",
            "1  rec_2  2025-10-26T00:00:00Z  line85_ord0  line85_ord0_p0  19.281079   \n",
            "2  rec_3  2025-10-27T00:00:00Z  line85_ord0  line85_ord0_p0  19.281079   \n",
            "3  rec_4  2025-10-28T00:00:00Z  line85_ord0  line85_ord0_p0  19.281079   \n",
            "4  rec_5  2025-10-29T00:00:00Z  line85_ord0  line85_ord0_p0  19.281079   \n",
            "\n",
            "         lon  epsg           sensor  resolution_m      NDVI  ...  score_BSI  \\\n",
            "0 -99.697361  4326  S1+S2_synthetic            10  0.574513  ...   0.417363   \n",
            "1 -99.697361  4326  S1+S2_synthetic            10  0.555201  ...   0.303721   \n",
            "2 -99.697361  4326  S1+S2_synthetic            10  0.559921  ...   0.347308   \n",
            "3 -99.697361  4326  S1+S2_synthetic            10  0.514147  ...   0.361979   \n",
            "4 -99.697361  4326  S1+S2_synthetic            10  0.585262  ...   0.386241   \n",
            "\n",
            "   score_NBR  score_clay  score_insar  score_amplitude  score_overall  \\\n",
            "0   0.037452    0.074776          1.0         0.446513       0.340149   \n",
            "1   0.157122    0.061819          1.0         0.403192       0.353115   \n",
            "2   0.158219    0.021435          1.0         0.385135       0.355681   \n",
            "3   0.169940    0.000000          1.0         0.424853       0.383636   \n",
            "4   0.190391    0.000000          1.0         0.097054       0.339294   \n",
            "\n",
            "                                               flags  seed  is_bad_track  \\\n",
            "0  [\"critical_threshold\", \"insar_critical\", \"synt...    42          True   \n",
            "1  [\"critical_threshold\", \"insar_critical\", \"synt...    42          True   \n",
            "2  [\"critical_threshold\", \"insar_critical\", \"synt...    42          True   \n",
            "3  [\"critical_threshold\", \"insar_critical\", \"synt...    42          True   \n",
            "4  [\"critical_threshold\", \"insar_critical\", \"synt...    42          True   \n",
            "\n",
            "                                               notes  \n",
            "0  synthetic generator; insar_rate_mm_per_year=33...  \n",
            "1  synthetic generator; insar_rate_mm_per_year=33...  \n",
            "2  synthetic generator; insar_rate_mm_per_year=33...  \n",
            "3  synthetic generator; insar_rate_mm_per_year=33...  \n",
            "4  synthetic generator; insar_rate_mm_per_year=33...  \n",
            "\n",
            "[5 rows x 33 columns]\n",
            "                lat           lon     epsg  resolution_m          NDVI  \\\n",
            "count  40006.000000  40006.000000  40006.0       40006.0  39599.000000   \n",
            "mean      23.124489   -101.703586   4326.0          10.0      0.492198   \n",
            "std        4.277967      5.487999      0.0           0.0      0.090954   \n",
            "min       14.709204   -117.022993   4326.0          10.0      0.107848   \n",
            "25%       19.597067   -104.725631   4326.0          10.0      0.412332   \n",
            "50%       22.244524   -101.029805   4326.0          10.0      0.488199   \n",
            "75%       26.359373    -98.829512   4326.0          10.0      0.577349   \n",
            "max       32.664913    -86.870212   4326.0          10.0      0.790839   \n",
            "\n",
            "               NDWI          NDMI           BSI           NBR     clay_frac  \\\n",
            "count  39599.000000  39599.000000  39599.000000  39599.000000  39599.000000   \n",
            "mean      -0.196142     -0.097587      0.003698      0.342901      0.020634   \n",
            "std        0.045336      0.027321      0.028402      0.050932      0.014128   \n",
            "min       -0.376643     -0.234806     -0.088034      0.160000      0.000000   \n",
            "25%       -0.230606     -0.114117     -0.009293      0.310503      0.009914   \n",
            "50%       -0.195611     -0.097641      0.000497      0.344454      0.019953   \n",
            "75%       -0.162173     -0.081079      0.010787      0.375602      0.029924   \n",
            "max       -0.037634      0.056907      0.333128      0.587541      0.107427   \n",
            "\n",
            "       ...    score_NDVI    score_NDWI    score_NDMI     score_BSI  \\\n",
            "count  ...  40006.000000  40006.000000  40006.000000  40006.000000   \n",
            "mean   ...      0.225889      0.046155      0.334106      0.028797   \n",
            "std    ...      0.183080      0.064027      0.045234      0.070365   \n",
            "min    ...      0.000000      0.000000      0.101351      0.000000   \n",
            "25%    ...      0.035972      0.000000      0.306913      0.000000   \n",
            "50%    ...      0.213081      0.000000      0.333846      0.001461   \n",
            "75%    ...      0.400327      0.084708      0.360950      0.031543   \n",
            "max    ...      1.000000      0.383937      0.601012      0.951795   \n",
            "\n",
            "          score_NBR    score_clay   score_insar  score_amplitude  \\\n",
            "count  40006.000000  40006.000000  4.000600e+04     40006.000000   \n",
            "mean       0.089729      0.051581  4.666685e-02         0.286559   \n",
            "std        0.068323      0.035302  1.700416e-01         0.170292   \n",
            "min        0.000000      0.000000  2.550000e-07         0.000016   \n",
            "25%        0.035040      0.024789  6.150551e-03         0.146790   \n",
            "50%        0.083460      0.049879  1.341406e-02         0.280932   \n",
            "75%        0.132641      0.074774  2.466726e-02         0.409523   \n",
            "max        0.378011      0.268568  1.000000e+00         0.876297   \n",
            "\n",
            "       score_overall     seed  \n",
            "count   40006.000000  40006.0  \n",
            "mean        0.142488     42.0  \n",
            "std         0.057371      0.0  \n",
            "min         0.037639     42.0  \n",
            "25%         0.102007     42.0  \n",
            "50%         0.135676     42.0  \n",
            "75%         0.171390     42.0  \n",
            "max         0.548121     42.0  \n",
            "\n",
            "[8 rows x 25 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Define Features and Target  \n",
        "These are the satellite-based variables used by the model:\n",
        "\n",
        "- **NDVI** â€“ vegetation index\n",
        "- **NDWI** â€“ water index\n",
        "- **NDMI** â€“ moisture index\n",
        "- **NBR** â€“ burn ratio (or analogous vegetation stress index)\n",
        "- **clay_frac** â€“ soil composition indicator\n",
        "- **Radar VV/VH/B bits** â€“ encoded backscatter values\n",
        "- **Scores** â€“ engineered features representing importance weights\n",
        "\n",
        "The target variable is:\n",
        "\n",
        "- **density** â€” continuous maintenance priority indicator\n"
      ],
      "metadata": {
        "id": "25eOdyp6YSAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 2. Define Features and Target\n",
        "# =====================================================\n",
        "\n",
        "features = [\n",
        "    \"NDVI\", \"NDWI\", \"NDMI\", \"NBR\",\n",
        "    \"clay_frac\",\n",
        "    \"mm_interval\", \"mm_cumulative\",\n",
        "    \"VV_bit\", \"VH_bit\", \"B_bit\",\n",
        "    \"score_NBR\", \"score_NDWI\", \"score_NDMI\",\n",
        "    \"score_NDVI\", \"score_clay\", \"score_amplitude\",\n",
        "]\n",
        "\n",
        "TARGET = \"score_overall\"\n",
        "\n",
        "X = df[features]\n",
        "y = df[TARGET].astype(float)\n",
        "\n",
        "print(\"Features and target successfully extracted.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgy9er43YBBC",
        "outputId": "f428d0db-25b7-4466-fd3a-a7b61b9fc05c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features and target successfully extracted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Train/Test Split\n",
        "\n",
        "We split the dataset as follows:\n",
        "\n",
        "- **80%** â†’ Training data  \n",
        "- **20%** â†’ Test data  \n",
        "- `random_state=42` ensures reproducibility  \n",
        "\n",
        "This allows us to evaluate how well the model generalizes to unseen segments.\n",
        "\n"
      ],
      "metadata": {
        "id": "MlPzXdtja_Ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 3. Train/Test Split\n",
        "# =====================================================\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training set:\", X_train.shape)\n",
        "print(\"Test set:\", X_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1ssOg_qaiD3",
        "outputId": "26e06857-b41b-485c-bfe1-656cf0d54931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: (32004, 16)\n",
            "Test set: (8002, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Train Random Forest Regressor\n",
        "\n",
        "We use a **RandomForestRegressor** because:\n",
        "\n",
        "- It handles non-linear relationships\n",
        "- Robust to noise\n",
        "- Minimal preprocessing required\n",
        "- Works well with engineered features\n",
        "\n",
        "Hyperparameters used:\n",
        "- `n_estimators = 300`\n",
        "- `max_depth = 14`\n",
        "- `random_state = 42`\n"
      ],
      "metadata": {
        "id": "h7D-nAEAY8GH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 4. Train Model\n",
        "# =====================================================\n",
        "\n",
        "model = RandomForestRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=14,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model successfully trained!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwO2PwdtbHk4",
        "outputId": "8a63b002-d260-4a4f-8598-c39a42dffce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model successfully trained!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Save Model  \n",
        "We export the trained model as:\n",
        "\n",
        "``density_regressor.pkl``\n",
        "\n",
        "This file can later be used for:\n",
        "- Inference on new satellite batches\n",
        "- Deployment on cloud pipelines\n",
        "- Integration with QGIS or Power BI\n"
      ],
      "metadata": {
        "id": "MfZ40CrzbK6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 5. Save Model\n",
        "# =====================================================\n",
        "\n",
        "joblib.dump(model, \"density_regressor.pkl\")\n",
        "print(\"Model saved as density_regressor.pkl\")\n"
      ],
      "metadata": {
        "id": "h_3bOrIKbKle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Model Evaluation\n",
        "\n",
        "We compute:\n",
        "\n",
        "- **MAE** â€“ Mean Absolute Error  \n",
        "- **RMSE** â€“ Root Mean Square Error  \n",
        "- **RÂ²** â€“ Coefficient of determination  \n",
        "\n",
        "These metrics help us confirm if the model is stable and reliable enough for operational use.\n"
      ],
      "metadata": {
        "id": "CNW0us5jeQNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 6. Evaluate Model\n",
        "# =====================================================\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r2  = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Model performance\")\n",
        "print(\"------------------\")\n",
        "print(f\"MAE  : {mae:.4f}\")\n",
        "print(f\"RMSE : {rmse:.4f}\")\n",
        "print(f\"RÂ²   : {r2:.4f}\")\n"
      ],
      "metadata": {
        "id": "kRaw4BSHbQrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Visualization â€” Predicted vs. True Density\n",
        "\n",
        "A 1:1 scatter plot helps us evaluate visually:\n",
        "- Error dispersion  \n",
        "- Under/over-estimation trends  \n",
        "- How well the model captures real patterns  \n",
        "\n",
        "Points closer to the diagonal are better predictions.\n"
      ],
      "metadata": {
        "id": "vwpQDZqabSx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 7. Visualization\n",
        "# =====================================================\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "plt.xlabel(\"True Density\")\n",
        "plt.ylabel(\"Predicted Density\")\n",
        "plt.title(\"Random Forest Regression: True vs Predicted Density\")\n",
        "\n",
        "# Optional: 1:1 reference line\n",
        "min_val = min(y_test.min(), y_pred.min())\n",
        "max_val = max(y_test.max(), y_pred.max())\n",
        "plt.plot([min_val, max_val], [min_val, max_val], \"k--\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GHQZSOf4bVt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“¥ Downloading the Original In-Situ Database from Zenodo\n",
        "\n",
        "The original in-situ dataset is stored on Zenodo.  \n",
        "Before adding new rows, we must download the official database directly from the record.\n",
        "\n",
        "### What this cell does\n",
        "1. Calls the Zenodo API for record **17688410**  \n",
        "2. Retrieves metadata (including all attached files)  \n",
        "3. Downloads every file associated with the record  \n",
        "4. Loads the main CSV into a pandas DataFrame called `original_data`\n",
        "\n",
        "This ensures that we always work with the **latest and official version** of the in-situ database.\n"
      ],
      "metadata": {
        "id": "TSAYJMscnRg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# ========================================================\n",
        "# 1. Zenodo API endpoint for the in-situ dataset\n",
        "#    This is the OFFICIAL record ID: 17688410\n",
        "# ========================================================\n",
        "api_url = \"https://zenodo.org/api/records/17688410\"\n",
        "\n",
        "print(\"ðŸ“¡ Fetching Zenodo metadata...\")\n",
        "record = requests.get(api_url).json()\n",
        "\n",
        "# ========================================================\n",
        "# 2. Download all files in the Zenodo deposit\n",
        "# ========================================================\n",
        "print(\"ðŸ“¥ Downloading all files from Zenodo record...\")\n",
        "\n",
        "for f in record[\"files\"]:\n",
        "    file_url = f[\"links\"][\"self\"] + \"?download=1\"\n",
        "    file_name = f[\"key\"]\n",
        "\n",
        "    print(f\"   â†’ Downloading {file_name}...\")\n",
        "    r = requests.get(file_url)\n",
        "\n",
        "    with open(file_name, \"wb\") as file:\n",
        "        file.write(r.content)\n",
        "\n",
        "print(\"âœ“ All files downloaded.\")\n",
        "\n",
        "# ========================================================\n",
        "# 3. Identify the main CSV in the downloaded files\n",
        "#    We assume the main database is the FIRST CSV in the folder.\n",
        "# ========================================================\n",
        "csv_files = [f for f in os.listdir() if f.endswith(\".csv\")]\n",
        "\n",
        "if not csv_files:\n",
        "    raise ValueError(\"âŒ No CSV files found after downloading Zenodo dataset.\")\n",
        "\n",
        "in_situ_filename = csv_files[0]\n",
        "print(\"ðŸ“‚ Using this file as the original in-situ database:\", in_situ_filename)\n",
        "\n",
        "# ========================================================\n",
        "# 4. Load the original database as pandas DataFrame\n",
        "# ========================================================\n",
        "original_data = pd.read_csv(in_situ_filename)\n",
        "\n",
        "print(\"âœ“ Original in-situ database loaded successfully.\")\n",
        "original_data.head()\n"
      ],
      "metadata": {
        "id": "HI4HFrwbt-Yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“¤ Upload New In-Situ Records (CSV)\n",
        "\n",
        "In this step, we upload a CSV file containing **new in-situ measurements**\n",
        "that will be appended to the original in-situ database.\n",
        "\n",
        "Requirements for the new file:\n",
        "\n",
        "- It must contain the **same columns as the original dataset**,  \n",
        "  **except** for the `sleeper_id` column.\n",
        "- Each row represents a new sleeper or new measurement to be added.\n",
        "\n",
        "We will:\n",
        "\n",
        "1. Upload the file via `files.upload()`  \n",
        "2. Load it into a DataFrame called `new_data`  \n",
        "3. Preview the first rows to verify correctness  \n"
      ],
      "metadata": {
        "id": "YGgUqHhcuDfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "print(\"ðŸ“¤ Upload the CSV file containing the new in-situ rows:\")\n",
        "\n",
        "uploaded_new = files.upload()\n",
        "\n",
        "# Extract the uploaded filename\n",
        "new_file_name = list(uploaded_new.keys())[0]\n",
        "print(f\"File received: {new_file_name}\")\n",
        "\n",
        "# Load into DataFrame\n",
        "new_data = pd.read_csv(new_file_name)\n",
        "\n",
        "print(\"âœ“ New in-situ data loaded into DataFrame.\")\n",
        "new_data.head()\n"
      ],
      "metadata": {
        "id": "7ylwuNNCuEav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ”Ž Validating Structure and Preparing `sleeper_id` for New Records\n",
        "\n",
        "Before merging, we must ensure that:\n",
        "\n",
        "- The **new data has the same columns as the original dataset**,  \n",
        "  excluding the `sleeper_id` column.\n",
        "- The **ID column is explicitly `sleeper_id`** in the original data.\n",
        "\n",
        "This step will:\n",
        "\n",
        "1. Check that `sleeper_id` exists in `original_data`  \n",
        "2. Compare expected columns (original columns without `sleeper_id`)  \n",
        "   vs. the columns in `new_data`  \n",
        "3. Raise a clear error if they do not match  \n",
        "4. Add an empty `sleeper_id` column to `new_data` so we can generate new IDs  \n"
      ],
      "metadata": {
        "id": "RBhDluD9uK_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# 1) Define the ID column for the in-situ dataset\n",
        "# ------------------------------------------------------------\n",
        "id_col = \"sleeper_id\"\n",
        "\n",
        "if id_col not in original_data.columns:\n",
        "    raise ValueError(f\"âŒ ERROR: Column '{id_col}' was not found in original_data.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) Validate that new_data has the same columns as original_data,\n",
        "#    except for 'sleeper_id'.\n",
        "# ------------------------------------------------------------\n",
        "expected_columns = [c for c in original_data.columns if c != id_col]\n",
        "new_columns = list(new_data.columns)\n",
        "\n",
        "if new_columns != expected_columns:\n",
        "    raise ValueError(\n",
        "        \"âŒ ERROR: The uploaded in-situ file does not match the expected structure.\\n\"\n",
        "        f\"Expected columns (without '{id_col}'): {expected_columns}\\n\"\n",
        "        f\"Received columns: {new_columns}\"\n",
        "    )\n",
        "\n",
        "print(\"âœ“ Column structure validated successfully (excluding 'sleeper_id').\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) Insert an empty 'sleeper_id' column into new_data\n",
        "#    so we can fill it with new IDs.\n",
        "# ------------------------------------------------------------\n",
        "new_data.insert(0, id_col, None)\n",
        "print(f\"âœ“ Temporary '{id_col}' column added to new_data.\")\n",
        "\n",
        "new_data.head()\n"
      ],
      "metadata": {
        "id": "30eSj6_huMXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ†” Generating New `sleeper_id` Values\n",
        "\n",
        "The original in-situ database uses `sleeper_id` as the primary identifier.\n",
        "\n",
        "We now:\n",
        "\n",
        "1. Read all existing `sleeper_id` values from `original_data`  \n",
        "2. Compute the maximum existing ID  \n",
        "3. Generate **new consecutive IDs** for `new_data`, starting from `max_id + 1`  \n",
        "\n",
        "Example:\n",
        "\n",
        "- If the largest existing `sleeper_id` is `3500`  \n",
        "- And the new file contains 10 rows  \n",
        "\n",
        "Then the new IDs will be:  \n",
        "\n",
        "`3501, 3502, 3503, ..., 3510`\n"
      ],
      "metadata": {
        "id": "BmSFuxpmuRrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Extract numerical part of sleeper_id safely.\n",
        "# Example: \"S_2000000\" â†’ 2000000\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "def extract_sleeper_number(sid):\n",
        "    try:\n",
        "        # Split by \"_\" and take the last element\n",
        "        # Works for formats like \"S_1234\", \"SL_9999\", etc.\n",
        "        return int(str(sid).split(\"_\")[-1])\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Apply extraction function\n",
        "id_numbers = original_data[\"sleeper_id\"].apply(extract_sleeper_number).dropna().astype(int)\n",
        "\n",
        "# Maximum existing ID\n",
        "max_existing_id = id_numbers.max()\n",
        "print(\"Last numeric sleeper_id:\", max_existing_id)\n",
        "\n",
        "# Number of new rows\n",
        "n_new = len(new_data)\n",
        "\n",
        "# Generate new numeric IDs\n",
        "new_numeric_ids = list(range(max_existing_id + 1, max_existing_id + 1 + n_new))\n",
        "\n",
        "# Rebuild full sleeper_id string with prefix \"S_\"\n",
        "new_ids = [f\"S_{num}\" for num in new_numeric_ids]\n",
        "\n",
        "# Assign to DataFrame\n",
        "new_data[\"sleeper_id\"] = new_ids\n",
        "\n",
        "print(\"âœ“ New 'sleeper_id' values generated successfully.\")\n",
        "new_data.head()\n"
      ],
      "metadata": {
        "id": "c5CCPjtkuRQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ”„ Merging and Saving the Updated In-Situ Database\n",
        "\n",
        "Now that:\n",
        "\n",
        "- The original in-situ dataset is loaded (`original_data`)  \n",
        "- The new in-situ rows are loaded (`new_data`)  \n",
        "- `sleeper_id` has been assigned correctly to all new rows  \n",
        "\n",
        "We can:\n",
        "\n",
        "1. Merge (`concat`) the original and new data  \n",
        "2. Save the updated in-situ database to a new CSV  \n",
        "3. Download the updated file for storage or future training  \n"
      ],
      "metadata": {
        "id": "xBqgD_2YuXgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Merge original data with the new in-situ rows\n",
        "# ------------------------------------------------------------\n",
        "updated_in_situ = pd.concat([original_data, new_data], ignore_index=True)\n",
        "\n",
        "print(\"âœ“ Original in-situ data and new rows successfully merged.\")\n",
        "print(\"Updated dataset shape:\", updated_in_situ.shape)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Define the filename for the updated in-situ dataset\n",
        "# ------------------------------------------------------------\n",
        "output_filename = \"in_situ_database_updated.csv\"\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Save to CSV (no index column)\n",
        "# ------------------------------------------------------------\n",
        "updated_in_situ.to_csv(output_filename, index=False)\n",
        "print(\"âœ“ Updated in-situ dataset saved as:\", output_filename)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Trigger download in Colab\n",
        "# ------------------------------------------------------------\n",
        "files.download(output_filename)\n"
      ],
      "metadata": {
        "id": "kxofH4L7uYdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸš§ In-Situ Rail Maintenance Classifier  \n",
        "Binary classification of GOOD vs BAD maintenance cycles based on machine sensor data.\n",
        "\n",
        "This section builds a RandomForest model using synthetic (or real) operational\n",
        "measurements extracted from a track maintenance machine.\n",
        "\n",
        "Workflow:\n",
        "1. Define sensor-based features  \n",
        "2. Generate or load data  \n",
        "3. Create labels (GOOD=0, BAD=1)  \n",
        "4. Check leakage  \n",
        "5. Visualize feature distributions  \n",
        "6. Train/test split  \n",
        "7. Train classifier  \n",
        "8. Save model and evaluate performance  \n"
      ],
      "metadata": {
        "id": "fqYgdo2Ngpz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n"
      ],
      "metadata": {
        "id": "9mDAgNrvjdN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Define Features  \n",
        "These are the machine-measured variables before and after a maintenance cycle.\n"
      ],
      "metadata": {
        "id": "mV9h-fydjmzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = [\n",
        "    \"pre_level_mm\",\n",
        "    \"post_level_mm\",\n",
        "    \"pre_align_mm\",\n",
        "    \"post_align_mm\",\n",
        "    \"gauge_mm\",\n",
        "    \"cant_mm\",\n",
        "    \"squeeze_pressure_bar\",\n",
        "    \"squeeze_angle_deg\",\n",
        "    \"lift_force_kN\",\n",
        "    \"align_force_kN\",\n",
        "    \"cycle_duration_ms\",\n",
        "]\n"
      ],
      "metadata": {
        "id": "rQZxtkgdkGv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Define Features and Target  \n",
        "These are the satellite-based variables used by the model:\n",
        "\n",
        "- **NDVI** â€“ vegetation index\n",
        "- **NDWI** â€“ water index\n",
        "- **NDMI** â€“ moisture index\n",
        "- **NBR** â€“ burn ratio (or analogous vegetation stress index)\n",
        "- **clay_frac** â€“ soil composition indicator\n",
        "- **Radar VV/VH/B bits** â€“ encoded backscatter values\n",
        "- **Scores** â€“ engineered features representing importance weights\n",
        "\n",
        "The target variable is:\n",
        "\n",
        "- **density** â€” continuous maintenance priority indicator\n"
      ],
      "metadata": {
        "id": "MDB1hu8zkJny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 2. Define Features and Target\n",
        "# =====================================================\n",
        "\n",
        "features = [\n",
        "    \"NDVI\", \"NDWI\", \"NDMI\", \"NBR\",\n",
        "    \"clay_frac\",\n",
        "    \"mm_interval\", \"mm_cumulative\",\n",
        "    \"VV_bit\", \"VH_bit\", \"B_bit\",\n",
        "    \"score_NBR\", \"score_NDWI\", \"score_NDMI\",\n",
        "    \"score_NDVI\", \"score_clay\", \"score_amplitude\",\n",
        "]\n",
        "\n",
        "TARGET = \"density\"\n",
        "\n",
        "X = df[features]\n",
        "y = df[TARGET].astype(float)\n",
        "\n",
        "print(\"Features and target successfully extracted.\")\n"
      ],
      "metadata": {
        "id": "FPW5zCJvmYqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Train/Test Split\n",
        "\n",
        "We split the dataset as follows:\n",
        "\n",
        "- **80%** â†’ Training data  \n",
        "- **20%** â†’ Test data  \n",
        "- `random_state=42` ensures reproducibility  \n",
        "\n",
        "This allows us to evaluate how well the model generalizes to unseen segments.\n"
      ],
      "metadata": {
        "id": "ZxMQYjWPmcOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 3. Train/Test Split\n",
        "# =====================================================\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training set:\", X_train.shape)\n",
        "print(\"Test set:\", X_test.shape)\n"
      ],
      "metadata": {
        "id": "CM-tanOammPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train Random Forest Regressor\n",
        "\n",
        "We use a **RandomForestRegressor** because:\n",
        "\n",
        "- It handles non-linear relationships\n",
        "- Robust to noise\n",
        "- Minimal preprocessing required\n",
        "- Works well with engineered features\n",
        "\n",
        "Hyperparameters used:\n",
        "- `n_estimators = 300`\n",
        "- `max_depth = 14`\n",
        "- `random_state = 42`\n"
      ],
      "metadata": {
        "id": "ta4FtvXKmogy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 4. Train Model\n",
        "# =====================================================\n",
        "\n",
        "model = RandomForestRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=14,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model successfully trained!\")\n"
      ],
      "metadata": {
        "id": "ux71IuIdmsha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Save Model  \n",
        "We export the trained model as:\n",
        "\n",
        "``density_regressor.pkl``\n",
        "\n",
        "This file can later be used for:\n",
        "- Inference on new satellite batches\n",
        "- Deployment on cloud pipelines\n",
        "- Integration with QGIS or Power BI\n"
      ],
      "metadata": {
        "id": "A9r8d2GAmwUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 5. Save Model\n",
        "# =====================================================\n",
        "\n",
        "joblib.dump(model, \"density_regressor.pkl\")\n",
        "print(\"Model saved as density_regressor.pkl\")\n"
      ],
      "metadata": {
        "id": "I2lU88n0myWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Model Evaluation\n",
        "\n",
        "We compute:\n",
        "\n",
        "- **MAE** â€“ Mean Absolute Error  \n",
        "- **RMSE** â€“ Root Mean Square Error  \n",
        "- **RÂ²** â€“ Coefficient of determination  \n",
        "\n",
        "These metrics help us confirm if the model is stable and reliable enough for operational use.\n"
      ],
      "metadata": {
        "id": "KvaqxZf0m0YU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 6. Evaluate Model\n",
        "# =====================================================\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r2  = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Model performance\")\n",
        "print(\"------------------\")\n",
        "print(f\"MAE  : {mae:.4f}\")\n",
        "print(f\"RMSE : {rmse:.4f}\")\n",
        "print(f\"RÂ²   : {r2:.4f}\")\n"
      ],
      "metadata": {
        "id": "2ZR9UJXnm2Z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Visualization â€” Predicted vs. True Density\n",
        "\n",
        "A 1:1 scatter plot helps us evaluate visually:\n",
        "- Error dispersion  \n",
        "- Under/over-estimation trends  \n",
        "- How well the model captures real patterns  \n",
        "\n",
        "Points closer to the diagonal are better predictions.\n"
      ],
      "metadata": {
        "id": "Dd-nudVNm4pG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 7. Visualization\n",
        "# =====================================================\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "plt.xlabel(\"True Density\")\n",
        "plt.ylabel(\"Predicted Density\")\n",
        "plt.title(\"Random Forest Regression: True vs Predicted Density\")\n",
        "\n",
        "# Optional: 1:1 reference line\n",
        "min_val = min(y_test.min(), y_pred.min())\n",
        "max_val = max(y_test.max(), y_pred.max())\n",
        "plt.plot([min_val, max_val], [min_val, max_val], \"k--\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "N3os2a9Om6fp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}